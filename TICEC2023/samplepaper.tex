% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{color}
% \renewcommand\UrlFont{\color{blue}\rmfamily}


\begin{document}

\title{Particle Filter and Support Vector Regression: Individual and collective performance}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
150--250 words.

\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%

\section{Introduction}
\label{sec:intro}
Los algoritmos Sequential Monte Carlo (SMC) son técnicas utilizados para simular muestras en forma secuencial a partir de distribuciones que evolucionan en el tiempo, se caracterizan por ser altamente flexibles y de extensa aplicabilidad en muchos campos de la ciencia.
 En particular, los filtros de partículas (PF) es un algoritmo SMC. Los PF fueron desarrollados en la década de los $(1990)$, por  Gordon et. al $(1993)$, Kitagawa $(1996)$, Del Moral $(1996)$, Doucet et. al $(2000)$, Doucet et. al $(2001)$, Godsill et. al $(2000)$, Ristic et. al $(2003)$, entre otros, con el propósito de aproximar distribuciones arbitrarias, posiblemente 
 multimodales y en espacios de alta dimensiones. El método consiste en generar un conjunto de muestras pesadas llamadas partículas y una
 distribución prior para aproximar la densidad a posterior de los estados desconocidos. El paso de predicción supone una recursión Markoviana que se actualiza en forma iterativa  sobre la base de los estados 
 predichos en tiempos pasados.\\
%\input{Sections/1_intro}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
\label{sec:related_work}
\input{Sections/2_related_work}

\section{Materials and Methods}
\label{sec:material_methods}

\subsection{SARIMA}
\input{Sections/4_1SARIMA}


\subsection{Support Vector Regression}
\input{Sections/4_SVR}


\subsection{Particle Filtering}
\input{Sections/3_PF}


\subsection{SVR-PF}
\input{Sections/5_SVR-PF}


\subsection{Data sets}
\input{Sections/6_datasets}

\subsection{Metrics}
\input{Sections/7_metrics}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Results}
\label{sec:results}
\input{Sections/8_results}


\section{Discussion}
\label{sec:discussion}
\input{Sections/9_discussion}


\section{Conclusions}
\label{sec:conclusions}
\input{Sections/10_conclusion}




\subsubsection{Acknowledgements} Please place your acknowledgments at
the end of the paper, preceded by an unnumbered run-in heading (i.e.
3rd-level heading).

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{bibliography}
%
\begin{enumerate}
\item Chai, T. and Draxler, R. R. $(2014)$. Root mean square error (RMSE) or mean absolute error (MAE)?. 
 Arguments against avoiding RMSE in the literature, Geosci. Model Dev., 7, 1247-1250,
  https://doi.org/10.5194/gmd-7-1247-2014.
  \item  Doucet, A; de Freitas, J;  Gordon, N. $(2001)$. An introduction to
sequential Monte Carlo methods, in Sequential Monte Carlo Methods
in Practice, A. Doucet, J. F. G. de Freitas, and N. J. Gordon, Eds. New
York: Springer-Verlag.
\item Arulampalam, M; Maskell, S;  Gordon, N;  Clapp, T. $(2002)$.
A Tutorial on Particle Filters for Online
Nonlinear/Non-Gaussian Bayesian Tracking.
IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2.
\item Ma, X; Karkus, P;  Hsu, D; Lee, W. $(2020)$.
Particle Filter Recurrent Neural Networks.
The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20).
 \item Kitagawa, G. $(1996)$. Monte Carlo filter and smoother for Non-Gaussian 
 nonlinear state space models. Journal of Computational and Graphical Statistics,
 5(1), 1–25.
 \item Jung, S;  Schlangen, I; Charlish, A. $(2019)$.
 Sequential Monte Carlo Filtering with Long
 Short-Term Memory Prediction. Conference: 22nd International
 Conference on Information FusionAt: Ottawa.
 \item  Gordon, N ; Salmond, D; Smith, A.F.M. $(1993)$.
 Novel approach to nonlinear/non-Gaussian Bayesian state estimation.
 Volume 140, Issue 2, p. 107-113.
 DOI:  10.1049/ip-f-2.1993.0015 , Print ISSN 0956-375X. 
 Online ISSN 2053-9045.
 \item Doucet, A; Godsill, S;  Andrieu, C. $(2000)$.
 On Sequential Monte Carlo Sampling Methods for Bayesian Filtering.
 Statistics and Computing. Volume 10, 3,197-208.
 \item Godsill, S; Arnaud Doucet; West, M. $(2004)$.
 Monte Carlo smoothing for nonlinear time series.
 Journal of the American Statistical Association, vol. 99, no. 465.
 \item  Ristic, B; Arulampalam, S;  Gordon, N. $(2003)$. Beyond the Kalman filter:
 Particle filters for tracking applications. Artech house.
  \item Choe, Y;  Shin, J;  Spencer, N. $(2017)$.
  Probabilistic Interpretations of Recurrent Neural Networks.
  Final Report, 10-708 Probabilistic Graphical Models.
  \item Cho, K; Bart van Merri$\ddot{e}$nboer, Caglar Gulcehre,
  Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio.
  $(2014)$. Learning phrase representations using rnn encoder–decoder
  for statistical machine translation. In Proceedings of the  Conference 
  on Empirical Methods in Natural Language Processing (EMNLP),
  pp. 1724–1734. Association
  for Computational Linguistics.
  URL http://www.aclweb.org/anthology/D14-1179.
  \item Hochreiter, S; and Schmidhuber, J. $(1997)$. 
  Long short-term memory. Neural computation, 9(8):1735–1780.
  \item  Liu, Y;  Cheng, J; Zhang, H;   Zou, H; Xion, N. $(2020)$.
  Long Short-Term Memory Networks Based on Particle Filter for
  Object Tracking. Digital Object Identifier 10.1109/ACCESS.2020.3041294.
  \item V. N. Vapnik, and A. Y. Chervonenkis. $(1964)$. A note on one class of perceptrons, 
  Automation and Remote Control, vol.25, pp. 821 837.
  \item  Muthukrishnan, R; Maryam Jamila, S .(2020).  Predictive Modeling Using Support Vector Regression.
 International Journal of Scientific and Technology Research. 9(2):4863-4865
  \item Bertsekas,D.P.$(1995)$. Nonlinear Programming. Belmont, MA:Athenas Scientific.
  \item Shawe-Taylor, J., and N. Cristianini. $(2004)$. Kernel Methods for Pattern Analysis, Cambridge, U.K.,
  and New York: Cambridge University Press.
  \item Mercer, J., $(1909)$.Functions of positive and negative type, and their connection with the theory of
  integral equations,”Transactions of the London Philosophical Society (A), vol. 209, pp. 415–446.
   \item Courant, R., and D. Hilbert. $(1970)$. Methods of Mathematical Physics, vol. I and II, New York:Wiley
 Interscience
 \item Aisyah, W.I.W.M.N.; Muhamad Safiih, L.; Razak, Z.; Nurul Hila, Z.;
 Abd Aziz, K.A.H.; Elayaraja, A.; Nor Shairah, A.Z, $(2021)$. Improved
of Forecasting Sea Surface Temperature based on Hybrid ARIMA and Vector 
Machines Model. Malays. J. Fundam. Appl. Sci,17, 609–620.
\item K Abdul Hamid, A.A.; Wan Mohamad Nawi, W.I.A.; Lola, M.S.; Mustafa, W.A.; Abdul Malik, S.M.; Zakaria, S.; Aruchunan, E.; Zainuddin, N.H.; Gobithaasan, R.U.;
Abdullah, M.T. $(2023)$. Improvement of Time Forecasting Models Using Machine Learning for Future Pandemic 
Applications Based on COVID-19 Data 2020–2022. Diagnostics, 13, 1121.
 https://doi.org/10.3390/ diagnostics13061121.
\item Dama, F; Sinoquet C. $(2021)$. Analysis and modeling to forecast in time series:
a systematic review. arXiv:2104.00164v1 [cs.LG].
\item Haykin, S. $(2009)$. Neural Networks and Learning Machines. Third Edition, Pearson Education, Inc., McMaster University, Hamilton.
\end{enumerate}
\end{document}
