Considérese el problema de estimación de observaciones generadas en forma secuencial, mediante una ecuación de transición que describe
 la distribución de un proceso de Markov oculto denotado por $\{x_{t},\quad t\in \mathbb{N}\}$, llamado vector de estados latentes (estados no observados), y una ecuación de observación que describe la verosimilitud de los datos medidos en tiempos discretos denotado por $\{y_{t},\quad t\in \mathbb{N}\}$. El modelo es definido en términos de las
 densidades de probabilidades:  
\begin{equation}\label{eq:ModeloEspacioEstado}
\begin{split}
x_{t}&= f(x_{t-1})+u_{t} \quad u_{t}\sim N(0,\sigma_{u}^{2}) \quad \textrm{ (state evolution density)} \\
y_{t}&= h(x_{t})+ v_{t} \quad v_{t}\sim N(0,\sigma_{v}^{2}) \quad \quad \textrm{(observation density)}
\end{split}
\end{equation}
 dónde $x_{t}\in \mathbb{R}^{n_{x}}$: representan los estados no observados del sistema,
 $y_{t}\in \mathbb{R}^{n_{y}}$: representan las observaciones en el tiempo $t$,
 $f(.), h(.)$: representan las funciones no lineales de los estados y de las observaciones,
 $u_{t}\in \mathbb{R}^{n_{u}},  v_{t}\in\mathbb{R}^{n_{v}}$: representa a los procesos de ruido blanco.
El interés recae en estimar los estados desconocidos
$\mathbf{x_{1:t}}=\{x_{1},\ldots x_{t}\}$ a partir de las mediciones
$\mathbf{y_{1:t}}=\{y_{1},\ldots y_{t}\}$.
La distribución conjunta de los estados y las observaciones puede obtenerse
 directamente por la regla de la cadena de probabilidad:
 \begin{align*}
 	p\left(x_{1:t},y_{1:t} \right)=f\left(x_{1}\right) 
 	\left(\prod_{k=2}^{t}  f\left(x_{k}|x_{k-1}\right) \right) 
 	\left(\prod_{k=1}^{t}h\left(y_{k}|x_{k}\right) \right) 
 \end{align*}
 where $f\left(x_{1}\right)$ is the distribution of the initial state.\\
 Para hacer inferencia basados en modelos espacio de estados, se lleva
 acabo mediante una estimación secuencial de la distribución filtrada
 $p(\mathbf{x}_{1:t}|y_{1:t})$, en particular,
interesa $p(x_{t}|\mathbf{y_{1:t})}$, que puede ser estimada en
dos etapas:
\begin{enumerate}
	\item \textbf{Analysis step:}
	\begin{equation}\label{eq:EcuacionDePrediccion}
	p(x_{t}|\mathbf{y_{1:t-1}}) =%
		\int p(x_{t-1}|\mathbf{y_{1:t-1}})f(x_{t}|x_{t-1})dx_{t-1}
	\end{equation}
	\item \textbf{Forecast step::}
	\begin{equation}\label{eq:EcuacionDeActualizacion}
		p(x_{t}|\mathbf{y_{1:t}}) =%
	\frac{h(y_{t}|x_{t})p(x_{t}|\mathbf{y_{1:t-1}})}
	{p(y_{t}|\mathbf{y_{1:t-1})}}
	\end{equation}
	donde:
	\begin{equation}\label{eq:PosteriorDeLosDatosDadosLosAnteriores}
		p(y_{t}|\mathbf{y_{1:t-1}})=\int h(y_{t}|x_{t})
		p(x_{t}|\mathbf{y_{1:t-1}})dx_{t}
	\end{equation}
\end{enumerate}
Para que esta inferencia se pueda realizar en modelos de alta dimensión, 
y con estructuras no lineales se han propuesto muchos técnicas de aproximaciones; 
en particular, se proponen utilizar los particle filtering methods, the filtering 
density is approximated with an empirical distribution formed from point masses,
 or particles. Suppose that we have at time $t-1$ weighted particles
 \begin{equation}
 \left\{\mathbf{x_{1:t-1}^{(i)}},\omega_{t-1}^{(i)}, i=1,\ldots,N \right\}
 \end{equation}
drawn from the smoothing density $p(x_{t-1}|\mathbf{y_{1:t-1}})$, 
We can consider this an empirical approximation for the density
made up of point masses,
\begin{equation}
p_{N}\left(x_{t-1}|\mathbf{y_{1:t-1}}\right) \approx \sum_{i=1}^{N}\omega_{t}^{(i)}\delta_{x_{t-1}^{(i)}}(x_{t-1}),\quad
 \sum_{i=1}^{N}\omega_{t}^{(i)}=1,\quad  \omega_{t}^{(i)}\geq 0
\end{equation}
where $\delta_{x_{t-1}^{(i)}}(x_{t-1})$ denotes the Dirac-delta function.
Si $\{\omega_{t}^{(i)},i=1,\ldots,N\}$, son elegidos adecuadamente
Crisan and Doucet, $2002$, probaron que:
\begin{equation}
\lim_{N\rightarrow\infty}p_{N}\left(x_{t}|\mathbf{y_{1:t}}\right)=p(x_{t}|\mathbf{y_{1:t}})
\end{equation}
To update the smoothing density from time $t-1$ to time $t$,
factorize it as
\begin{equation}
	p_{N}\left(x_{t}|\mathbf{y_{1:t}}\right)=p_{N}\left(x_{t-1}|\mathbf{y_{1:t-1}}\right)
	\frac{h\left(y_{t}|x_{t}\right)f\left(x_{t}|x_{t-1}\right)}{p\left(y_{t}|\mathbf{y_{1:t-1}}\right) }
\end{equation}
We select $N$ trajectories are drawn at random with replacement from 
$\left\{\mathbf{x_{1:t}^{(i)}}, i=1,\ldots,N \right\}$
with probabilities $\left\{\mathbf{\omega_{t}^{(i)}}, i=1,\ldots,N \right\}$. 
A new state is then generated randomly from an importance distribution,
$q(x_{t}|x_{t-1}, y_{t})$, and appended to the corresponding trajectory,
$x_{t-1}$. The importance weight is updated to:
\begin{equation}
\omega_{t}^{(i)}=\frac{h(y_{t}|x_{t}^{(i)})f(x_{t}^{(i)}|x_{t-1}^{(i)})}
{q(x_{t}^{(i)}|x_{t-1}^{(i)},y_{t})}\omega_{t-1}^{(i)}
\end{equation}
where:
\begin{equation}
\omega_{t-1}^{(i)} = \frac{p(x_{t-1}^{(i)}|\mathbf{y_{1:t-1}})}
{q(x_{t-1}^{(i)}|\mathbf{y_{1:t-1}})}\\
\end{equation}
then
\begin{equation}
p_{N}(x_{t}|\mathbf{y_{1:t}}) \approx \sum_{i=1}^{N}\omega_{t}^{(i)}\delta_{x_{t}^{(i)}}\left(x_{t}\right) 
\end{equation}
Given at time $t-1$, $N\in \mathbb{N}$ random samples $\{\mathbf{x}_{1:t-1}^{(i)}\}$ distributed 
approximately according to $p\left(x_{t-1}|\mathbf{y_{1:t-1}} \right) $, the Monte Carlo filter 
proceeds as follows at time $t$:
\begin{enumerate}
\item [\bf Step 1:] Sequential Importance Sampling 
\begin{itemize}
\item Generate $N$ i.i.d. samples $\{\tilde{x}_{t}^{(i)},i=1,\ldots,N \}$  
from the proposal density $q(x)$: 
\begin{align*}
\tilde{x}_{t}^{(i)}\sim
q(x_{t}|\mathbf{x_{1:t-1}^{(i)},y_{1:t}})=f(x_{t}|\tilde{x}_{t-1}^{(i)})+u_{t}^{(i)}
\quad,\quad u_{t}^{(i)} \sim N(0,\sigma_{u}^{2})
\end{align*}
and set $\mathbf{\tilde{x}_{1:t}^{(i)}=\{x_{1:t-1}^{(i)}},\tilde{x}_{t}^{(i)}\}$.
\item For $i=1,...,N$, evaluate the importance weights up to a normalizing constant
\begin{align*}
\omega_{t}^{(i)}\propto 
\frac{h\left(y_{t}|\mathbf{y_{1:t-1}}, \mathbf{\tilde{x}_{1:t}^{(i)}} \right)f\left(\tilde{x}_{t}^{(i)}| \tilde{x}_{t-1}^{(i)}\right) }
{q(x_{t}|\mathbf{x_{1:t-1}^{(i)},y_{1:t}}) }
\end{align*}
	\item For $i=1,...,N$, normalize the importance weights:
	\begin{align*}
		\tilde{\omega}_{t}^{(i)}=\frac{\omega_{t}^{(i)}}{\sum_{j=1}^{N}\omega_{t}^{(j)}}
		\quad,\quad\sum_{i=1}^{N}\tilde{\omega}_{t}^{(i)}=1
	\end{align*}
\item Evaluate $\hat{N}_{eff}=\frac{1}{\sum_{i=1}^{N}[\tilde{w}_{t}^{(i)}]^{2}}$
\end{itemize}
\item [\bf Step 2] Resampling
\begin{itemize}
\item If $\hat{N}_{eff}\geq  N_{thres}$, 
\begin{align*}
	x_{1:t}^{(i)}=\tilde{x}_{1:t}^{(i)},\quad for \quad i=1,\ldots,N
\end{align*}
otherwise
\item For $i=1,...,N$, sample an index $j(i)$ distributed according
to the discrete distribution with $N$ elements satisfying
\begin{align*}
p\left(j(i)=l \right) =\tilde{\omega}_{t}^{(l)},\quad for \quad l=1,\ldots,N
\end{align*}
\item For $i=1,...,N$,  $ \mathbf{x_{1:t}^{(i)}}=\mathbf{\tilde{x}_{1:t}}^{j(i)}$
and $\tilde{w}_{t}^{(i)}=\frac{1}{N}$.
\end{itemize}
\end{enumerate}